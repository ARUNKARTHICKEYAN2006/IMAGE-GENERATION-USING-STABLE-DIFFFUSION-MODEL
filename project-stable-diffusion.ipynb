{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5767025,"sourceType":"datasetVersion","datasetId":3314683}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-31T05:40:10.468927Z","iopub.execute_input":"2025-12-31T05:40:10.469201Z","execution_failed":"2025-12-31T05:41:26.958Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nos.listdir(\"/kaggle/input\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T05:42:00.468434Z","iopub.execute_input":"2025-12-31T05:42:00.468984Z","iopub.status.idle":"2025-12-31T05:42:00.478669Z","shell.execute_reply.started":"2025-12-31T05:42:00.468954Z","shell.execute_reply":"2025-12-31T05:42:00.477856Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nos.path.exists(\"/kaggle/input/ava-aesthetic-visual-assessment\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T05:42:03.540021Z","iopub.execute_input":"2025-12-31T05:42:03.540597Z","iopub.status.idle":"2025-12-31T05:42:03.545221Z","shell.execute_reply.started":"2025-12-31T05:42:03.540567Z","shell.execute_reply":"2025-12-31T05:42:03.544472Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.listdir(\"/kaggle/input/ava-aesthetic-visual-assessment\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T05:42:05.361765Z","iopub.execute_input":"2025-12-31T05:42:05.362045Z","iopub.status.idle":"2025-12-31T05:42:05.379375Z","shell.execute_reply.started":"2025-12-31T05:42:05.362020Z","shell.execute_reply":"2025-12-31T05:42:05.378854Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.listdir(\"/kaggle/input/ava-aesthetic-visual-assessment\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T05:43:27.892453Z","iopub.execute_input":"2025-12-31T05:43:27.893038Z","iopub.status.idle":"2025-12-31T05:43:27.897543Z","shell.execute_reply.started":"2025-12-31T05:43:27.893010Z","shell.execute_reply":"2025-12-31T05:43:27.897030Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nbase = \"/kaggle/input/ava-aesthetic-visual-assessment\"\nos.listdir(base)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T05:43:36.449335Z","iopub.execute_input":"2025-12-31T05:43:36.449616Z","iopub.status.idle":"2025-12-31T05:43:36.458781Z","shell.execute_reply.started":"2025-12-31T05:43:36.449591Z","shell.execute_reply":"2025-12-31T05:43:36.458248Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for item in os.listdir(base):\n    path = os.path.join(base, item)\n    print(item, \"-> directory\" if os.path.isdir(path) else \"-> file\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T05:43:41.196892Z","iopub.execute_input":"2025-12-31T05:43:41.197198Z","iopub.status.idle":"2025-12-31T05:43:41.203516Z","shell.execute_reply.started":"2025-12-31T05:43:41.197172Z","shell.execute_reply":"2025-12-31T05:43:41.202945Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img_dir = \"/kaggle/input/ava-aesthetic-visual-assessment/images\"\nos.listdir(img_dir)[:5]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T05:43:43.234406Z","iopub.execute_input":"2025-12-31T05:43:43.234714Z","iopub.status.idle":"2025-12-31T05:43:45.202010Z","shell.execute_reply.started":"2025-12-31T05:43:43.234686Z","shell.execute_reply":"2025-12-31T05:43:45.201435Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom PIL import Image\nimport os\n\nimg_dir = \"/kaggle/input/ava-aesthetic-visual-assessment/images\"\nfiles = os.listdir(img_dir)\n\nimg = Image.open(os.path.join(img_dir, files[0]))\n\nplt.imshow(img)\nplt.axis(\"off\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T05:43:48.110754Z","iopub.execute_input":"2025-12-31T05:43:48.111484Z","iopub.status.idle":"2025-12-31T05:43:50.473737Z","shell.execute_reply.started":"2025-12-31T05:43:48.111456Z","shell.execute_reply":"2025-12-31T05:43:50.472980Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!nvidia-smi\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T05:43:54.060177Z","iopub.execute_input":"2025-12-31T05:43:54.060473Z","iopub.status.idle":"2025-12-31T05:43:54.288087Z","shell.execute_reply.started":"2025-12-31T05:43:54.060449Z","shell.execute_reply":"2025-12-31T05:43:54.287248Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\n\n# Paths\nDATA_ROOT = \"/kaggle/input/ava-aesthetic-visual-assessment\"\nIMG_DIR = f\"{DATA_ROOT}/images\"\nCSV_PATH = f\"{DATA_ROOT}/ground_truth_dataset.csv\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T07:25:17.876705Z","iopub.execute_input":"2025-12-31T07:25:17.877388Z","iopub.status.idle":"2025-12-31T07:25:30.158750Z","shell.execute_reply.started":"2025-12-31T07:25:17.877361Z","shell.execute_reply":"2025-12-31T07:25:30.158132Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the AVA CSV\ndf = pd.read_csv(CSV_PATH)\nprint(df.head())\nprint(df.columns)  # check columns to see 'image_num', 'vote_1'..'vote_10'\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T07:25:30.159962Z","iopub.execute_input":"2025-12-31T07:25:30.160350Z","iopub.status.idle":"2025-12-31T07:25:31.053413Z","shell.execute_reply.started":"2025-12-31T07:25:30.160326Z","shell.execute_reply":"2025-12-31T07:25:31.052569Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True  # ignore truncated images\n\nclass AVADataset(Dataset):\n    def __init__(self, df, img_dir, transform=None):\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n        self.vote_cols = [f\"vote_{i}\" for i in range(1, 11)]\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img_name = str(int(self.df.iloc[idx]['image_num'])) + \".jpg\"\n        img_path = os.path.join(self.img_dir, img_name)\n\n        try:\n            image = Image.open(img_path).convert(\"RGB\")\n        except:\n            new_idx = np.random.randint(0, len(self.df))\n            return self.__getitem__(new_idx)\n\n        votes = self.df.iloc[idx][self.vote_cols].values.astype(float)\n        total_votes = votes.sum()\n        mean_score = sum((i+1)*votes[i] for i in range(10)) / total_votes\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, torch.tensor(mean_score, dtype=torch.float32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T07:25:36.969484Z","iopub.execute_input":"2025-12-31T07:25:36.969808Z","iopub.status.idle":"2025-12-31T07:25:36.976769Z","shell.execute_reply.started":"2025-12-31T07:25:36.969781Z","shell.execute_reply":"2025-12-31T07:25:36.976177Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T07:25:38.598546Z","iopub.execute_input":"2025-12-31T07:25:38.599204Z","iopub.status.idle":"2025-12-31T07:25:38.603061Z","shell.execute_reply.started":"2025-12-31T07:25:38.599174Z","shell.execute_reply":"2025-12-31T07:25:38.602407Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"subset_size = 20000  # pick 20k images for fast demo\ndf_subset = df.sample(n=subset_size, random_state=42).reset_index(drop=True)\n\ndataset = AVADataset(df_subset, IMG_DIR, transform)\nloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T07:25:41.093003Z","iopub.execute_input":"2025-12-31T07:25:41.093620Z","iopub.status.idle":"2025-12-31T07:25:41.113155Z","shell.execute_reply.started":"2025-12-31T07:25:41.093590Z","shell.execute_reply":"2025-12-31T07:25:41.112522Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class AestheticModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.backbone = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n        self.backbone.fc = nn.Linear(512, 1)\n\n    def forward(self, x):\n        return self.backbone(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T07:25:43.351048Z","iopub.execute_input":"2025-12-31T07:25:43.351722Z","iopub.status.idle":"2025-12-31T07:25:43.355864Z","shell.execute_reply.started":"2025-12-31T07:25:43.351692Z","shell.execute_reply":"2025-12-31T07:25:43.355185Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = AestheticModel().to(device)\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T07:25:48.092980Z","iopub.execute_input":"2025-12-31T07:25:48.093648Z","iopub.status.idle":"2025-12-31T07:25:49.003886Z","shell.execute_reply.started":"2025-12-31T07:25:48.093621Z","shell.execute_reply":"2025-12-31T07:25:49.003214Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"EPOCHS = 1 # fast demo\n\nfor epoch in range(EPOCHS):\n    model.train()\n    running_loss = 0.0\n\n    for imgs, scores in loader:\n        imgs = imgs.to(device)\n        scores = scores.to(device).unsqueeze(1)\n\n        preds = model(imgs)\n        loss = criterion(preds, scores)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    print(f\"Epoch {epoch+1} | Loss: {running_loss/len(loader):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T07:28:19.340699Z","iopub.execute_input":"2025-12-31T07:28:19.341225Z","iopub.status.idle":"2025-12-31T07:31:34.148177Z","shell.execute_reply.started":"2025-12-31T07:28:19.341196Z","shell.execute_reply":"2025-12-31T07:31:34.147245Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model.state_dict(), \"aesthetic_model.pth\")\nprint(\"Aesthetic scoring model saved!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T07:26:02.759072Z","iopub.execute_input":"2025-12-31T07:26:02.759776Z","iopub.status.idle":"2025-12-31T07:26:02.826147Z","shell.execute_reply.started":"2025-12-31T07:26:02.759746Z","shell.execute_reply":"2025-12-31T07:26:02.825408Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install diffusers transformers accelerate safetensors --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T07:26:04.961209Z","iopub.execute_input":"2025-12-31T07:26:04.961836Z","iopub.status.idle":"2025-12-31T07:26:10.587751Z","shell.execute_reply.started":"2025-12-31T07:26:04.961803Z","shell.execute_reply":"2025-12-31T07:26:10.586726Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from diffusers import StableDiffusionPipeline\nimport torch\n\npipe = StableDiffusionPipeline.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\",\n    torch_dtype=torch.float16\n).to(\"cuda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T07:26:10.589532Z","iopub.execute_input":"2025-12-31T07:26:10.589887Z","iopub.status.idle":"2025-12-31T07:27:31.295326Z","shell.execute_reply.started":"2025-12-31T07:26:10.589855Z","shell.execute_reply":"2025-12-31T07:27:31.294719Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt = \"a realistic portrait of a smiling woman, studio lighting\"\nimage = pipe(prompt).images[0]\nimage","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T07:27:52.020272Z","iopub.execute_input":"2025-12-31T07:27:52.021423Z","iopub.status.idle":"2025-12-31T07:28:01.566879Z","shell.execute_reply.started":"2025-12-31T07:27:52.021389Z","shell.execute_reply":"2025-12-31T07:28:01.566002Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt = \"A calm beach during sunset, waves gently crashing, ultra-detailed\"\nimage = pipe(prompt).images[0]\nimage","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T07:31:34.149872Z","iopub.execute_input":"2025-12-31T07:31:34.150147Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt = \"a beautiful landscape with mountains and lake, realistic lighting\"\nimage = pipe(prompt).images[0]\nimage\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T07:28:10.129886Z","iopub.execute_input":"2025-12-31T07:28:10.130188Z","iopub.status.idle":"2025-12-31T07:28:17.670846Z","shell.execute_reply.started":"2025-12-31T07:28:10.130163Z","shell.execute_reply":"2025-12-31T07:28:17.670083Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()  # ensure model is in eval mode\n\ndef aesthetic_score(image):\n    img_tensor = transform(image).unsqueeze(0).to(device)\n    with torch.no_grad():\n        score = model(img_tensor)\n    return score.item()\n\nscore = aesthetic_score(image)\nprint(\"Aesthetic Score:\", score)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T06:23:35.145383Z","iopub.execute_input":"2025-12-31T06:23:35.146025Z","iopub.status.idle":"2025-12-31T06:23:35.158815Z","shell.execute_reply.started":"2025-12-31T06:23:35.145995Z","shell.execute_reply":"2025-12-31T06:23:35.158215Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -------------------------------\n# EVALUATION USING MSE\n# -------------------------------\n\nmodel.eval()  # switch to evaluation mode\n\ntotal_mse = 0.0\nnum_batches = 0\n\nwith torch.no_grad():  # no gradients during evaluation\n    for imgs, scores in loader:\n        imgs = imgs.to(device)\n        scores = scores.to(device).unsqueeze(1)\n\n        preds = model(imgs)\n        mse = criterion(preds, scores)\n\n        total_mse += mse.item()\n        num_batches += 1\n\nfinal_mse = total_mse / num_batches\n\nprint(f\"Final Evaluation MSE: {final_mse:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T06:23:40.146440Z","iopub.execute_input":"2025-12-31T06:23:40.146704Z","iopub.status.idle":"2025-12-31T06:25:08.179021Z","shell.execute_reply.started":"2025-12-31T06:23:40.146682Z","shell.execute_reply":"2025-12-31T06:25:08.178291Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}